
%%%%%%%%%%%%%%%%%%%%%%% file typeinst.tex %%%%%%%%%%%%%%%%%%%%%%%%%
%
% This is the LaTeX source for the instructions to authors using
% the LaTeX document class 'llncs.cls' for contributions to
% the Lecture Notes in Computer Sciences series.
% http://www.springer.com/lncs       Springer Heidelberg 2006/05/04
%
% It may be used as a template for your own input - copy it
% to a new file with a new name and use it as the basis
% for your article.
%
% NB: the document class 'llncs' has its own and detailed documentation, see
% ftp://ftp.springer.de/data/pubftp/pub/tex/latex/llncs/latex2e/llncsdoc.pdf
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{epstopdf}


%\usepackage[german]{babel}
\usepackage[]{algorithmic}
\usepackage[]{algorithm}
\usepackage{multirow}

%\usepackage{amsthm}

\usepackage{url}
\urldef{\mailsa}\path|zheng.haitao@sz.tsinghua.edu.cn|
\urldef{\mailsb}\path|lizhuo13@mails.tsinghua.edu.cn|
%\urldef{\mailsc}\path|erika.siebert-cole, peter.strasser, lncs}@springer.com|    
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}
\floatname{algorithm}{Algorithm}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{document}

\mainmatter % start of an individual contribution

% first the title is needed
\title{iCHUM: An Efficient Algorithm for High Utility Mining in Incremental Databases}

% a short form should be given in case it is too long for the running head
\titlerunning{iCHUM: High Utility Mining in Incremental Databases}

% the name(s) of the author(s) follow(s) next
%
% NB: Chinese authors should write their first names(s) in front of
% their surnames. This ensures that the names appear correctly in
% the running heads and the author index.
%
\author{Hai-Tao Zheng%
%\thanks{Tel.: +8675526036076; fax: +8675526036761}%
\and ZHuo Li}
%
\authorrunning{iCHUM: High Utility Mining in Incremental Databases}
% (feature abused for this document to repeat the title also on left hand pages)

% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published
\institute{Graduate School at Shenzhen, Tsinghua University, \\
Building H,Tsinghua Campus,University Town,Shenzhen, China\\
\mailsa\\
\mailsb\\}
%\mailsc\\

%\url{http://www.springer.com/lncs}}

%
% NB: a more complex sample for affiliations and the mapping to the
% corresponding authors can be found in the file "llncs.dem"
% (search for the string "\mainmatter" where a contribution starts).
% "llncs.dem" accompanies the document class "llncs.cls".
%

\toctitle{iCHUM: An Efficient Algorithm for High Utility Mining in Incremental Databases}
\tocauthor{Hai-Tao Zheng and ZHuo Li}
\maketitle


\begin{abstract}
High utility mining is a fundamental topic in association rule, which aims to discover all itemsets with high utility from transaction database. Although a number of related methods have been proposed in recent years, they suffer from inefficiency in the incremental databases mining due to reconstruction of the whole data structure. In this paper, we propose our iCHUM-Tree and iCHUM algorithm to address the problem. The iCHUM algorithm maintains necessary items for mining procedure. And it reuse data structure from previous database and update iCHUM-Tree under incremental database environment. Performace analysis shows that our tree structre is efficient for high utility mining in incremental databases.
%\emph{abstract} environment.
%141 words && to be modified
\keywords{Association Rule, High Utility Mining, Incremental Mining.}
\end{abstract}


\section{Introduction}
Mining association rule is a fundamental topic in the data mining applications, especially in market analysis. In association rule mining, frequent pattern mining was firstly proposed to find all itemsets which frequently appear together in the transaction database. The initial solution is based on downward closure property \cite{Agrawal:fast}, which is a level-wise approach. However, it requires multiple database scans and generates a large number of candidate itemsets to search and identity. Extensive study \cite{Han:FIMwithoutcand} has been proposed to address the problem by introducing frequent pattern (FP) tree structure and corresponding FP-growth algorithm, which is a pattern-growth approach. The main difference between both approaches is whether the database is compressed into other data structure.

However, FP mining is prone to generate many frequent but low profitable itemsets. The reason is that FP mining treats all items with the same weight, and each item appears in binary format. In fact, weight and quantity are significant for addressing the decision problems in the real world where sellers require maximizing profit/utility from transaction records.

A high utility mining model \cite{Liu:two-phasewithCCPD} was defined to discover high utility patterns from the transaction databases. The significance of itemsets is measured by the concept of utility, which can be represented as profit. An itemset is called a high utility itemset if its utility is no less than a user-specified minimum utility threshold ($ min\_util $). Moreover, most previous studies \cite{Lin:for-um,Liu:two-phasewithCCPD,Tseng:up-growth} are based on a fixed transaction database and have not taken dynamic change of databases into consideration. In practice, the real markets add their transaction records incrementally, where there are incremental databases instead of fixed ones to be analyzed. 

Studies \cite{Ahmed:IHUP,Lin:dynamic-databases,Lin:incremental-hui,Yeh:IUM} put their concentration on incremental databases. However, IUM and FIUM algorithm \cite{Yeh:IUM} mines high temporal utility itemsets, which may be not high in the whole database. Though FUP-HU \cite{Lin:dynamic-databases,Lin:incremental-hui} addresses the above shortage, it becomes inefficient especially when the length of high utility pattern is large due to multiple scans of the whole database. IHUP \cite{Ahmed:IHUP} is a pattern-growth solution for high utility mining in incremental databases. It compresses databases into the IHUP-Tree and avoid multiple scans. Especially, it could add new transactions without reconstruction of the whole pattern tree. However, it becomes inefficient when the number of items in database is relatively large. In fact, not all items have to be maintained in pattern tree according to transaction-wighted downward closure (TWDC) property \cite{Liu:two-phasewithCCPD}. For that we propose a compressed high utility mining algorithm for incremental databases, abbreviated as iCHUM, and the corresponding pattern structure named iCHUM-Tree.

%fill your main work!!!! 
In this paper, we have two main contributions.

First, we propose an efficient algorithm iCHUM for mining high utility itemsets from incremental databases. The algorithm performs better when there are more items in the transaction database.

Second, we conduct a series of experiments on both real and synthetic datasets. We compare the performance between ours and IHUP under incremental databases and analyze the comparison of results.

The rest of this paper is organized as follows. In Section 2, we introduce the related work. In Section 3, we propose our pattern structure and algorithm in details after the problem definition. The experimental results and evaluations are shown in Section 4 and the conclusions are give in the Section 5.

\section{Related Work}
\subsection{High Utility Mining}
The definition of utility mining problem was given in \cite{Liu:two-phasewithCCPD}, which is similar to what we have adopted. In their work, they proposed the Two-Phase algorithm and introduced transaction-weighted utilization (TWU), which satisfies the downward closure property. The Two-Phase algorithm finds all high TWU 1-itemsets and then generates 2-itemset candidates for testing if there exists high TWU 2-itemsets. In that way, it finds all high TWU itemsets level by level, and needs to identify the candidates to determine the high utility itemsets. The algorithm suffers from multiple scans of database. Studies \cite{Ahmed:IHUP,Lin:for-um,Tseng:up-growth} are proposed together with their corresponding pattern data structure as pattern-growth approaches. These approaches scan the database to build up their pattern data structure separately at first. Then high TWU itemsets are generated by mining the compressed pattern structure instead of the whole database. They perform better in the relatively dense or long pattern databases. However, most pattern growth methods above are designed for fixed databases. Their pattern structure needs to be reconstructed once the database is updated.

%To efficiently generate the HTWUIs and avoid multiple database scan, Ahmed\cite{Ahmed:IHUP} proposed an efficient tree structure, named IHUP-Tree. Each node in IHUP-Tree consists of item name, its support count, and its TWU value. Further, Tseng\cite{Tseng:up-growth} reduce the estimated utility values by applying four strategies. A data structure named UP-Tree is proposed. They discard global unpromising items (DGU) and decrease global node utility (DGN) in construction of a global UP-Tree. The corresponding mining algorithm is called UP-Growth. During the mining process, they discard local unpromising items (DLU) and decrease local node utility (DLN) to enhance the mining performance. Based on \cite{Tseng:up-growth}, Wu\cite{Wu:topK} goes further and proposes TKU algorithm to mine top-K high utility itemsets. They apply five effective strategies not limited to the construction of the tree structure and generation of the candidates. Their strategies span from the period before the construction of the UP-Tree till the accomplishment phase II. The general framework of  \cite{Ahmed:IHUP} \cite{Tseng:up-growth} \cite{Wu:topK} are based on pattern-growth method, which consists of three steps: 1) the construction of the data structure, 2) the generation of the candidates and 3) identification of high utility itemsets, where step 1 and step 2 is phase I and step 3 is phase II. The performance is subject to the whole process including phase I and II. Fewer candidates generated during phase I would reduce the time of identification in phase II. Still their strategies produce too many candidates of high utility itemsets.

\subsection{High Utility Mining in Incremental Databases}
%incremental mining
There are some researches focus on high utility itemset mining for incremental database. Yeh et al. \cite{Yeh:IUM} proposed two methods: incremental utility mining (IUM) algorithm and fast incremental utility mining (FIUM) algorithm. However, these algorithm find high temporal utility itemsets, which is high utility itemsets in the part of the database. When parts joint into the whole, some of high temporal utility itemsets may not be high utiltity ones. 

Lin et al. \cite{Lin:dynamic-databases,Lin:incremental-hui} proposed an incremental updated HUP maintenance algorithm to address the mining process for incremental databases. It is necessary to find low TWU items back from original database since they may become high ones after the new transactions inserted. They divide the incremental databases into four cases when new transactions are inserted into an original database. What needs to be recalled is that items with low TWU in original database and high TWU in new database. However, their algorithm suffers from multiple scans and excessive candidates.

Ahmed \cite{Ahmed:IHUP} proposed their incremental mining method IHUP based on the IHUP-Tree structure. The IHUP-Tree maintains all of the items, and thus it inserts new transaction records without rebuilding the whole tree. All it needs is to maintain the order of the items by TWU and it is convenient for mining procedure. Limited to the property of their data structure, the efficiency of the algorithm is not satisfactory when the number of items is large or number of high TWU items is small. On those conditions, IHUP should maintain unnecessary insert or reorder operation for those low utility items.

%introduce our work. find shortcoming of theirs.
%1. new tree structure and mining process
%2. increamental database
Our proposed iCHUM method aims to improve time efficiency by maintaining promising items which may be high utility ones only. When the database grows incrementally, we find back those promising items with low TWU in original database and insert them to our iCHUM-Tree for utility mining without rebuiding the whole pattern structure.

\section{Proposed Method}
%This is my method.
%In this section, we first describe the problem definition of the high utility mining. Then, we introduce our framework of the iCHUM which is consisted of data structure and mining algorithm.

\subsection{Problem Definition}
%Definition
Let $ I = \{i_{1},i_{2},\ldots,i_{m}\} $ be a finite item set. Each item has its profit $p(i_{j})$ where $ 1{\le}j{\le}m$. A transaction database consists of a finite set of transaction records $ D = \{T_{1},T_{2},\ldots,T_{n}\} $ and item profit table. Each transaction $ T_{s} = \{ {i_{s}}_{1},{i_{s}}_{2},\ldots,{i_{s}}_{t} \} \subseteq I$ where $1{\le}s{\le}n, 1{\le}t{\le}m$. In $ T_{s} $, each item has its quantity $ q(i_{j},T_{s}) $ where $ 1{\le}j{\le}m, 1{\le}s{\le}n$. Let Table~\ref{table:1} be an example of database and Table~\ref{table:2} be an profit table.

An itemset $ X = \{{i_{j}}_{1},{i_{j}}_{2},\ldots,{i_{j}}_{l}\} \subseteq I $, where $ 1{\le}l{\le}m $, and $ l $ is the length of itemset $ X $. $ \forall i_{j} \in X$  if $ i_{j} \in T_{s}$, then the itemset $ X \subseteq T_{s} $, or $ T_{s} $ contains $ X $.

\begin{table}
\begin{minipage}[t]{.45\linewidth}
\centering
\caption{transaction database }
\begin{tabular}{ cc|c|l|c |} 
\cline{3-5} & & \textbf{Tid} & \multicolumn{1}{c|}{\textbf{Transaction}} & \textbf{TU} \\ 
\cline{3-5} 
\cline{3-5} {\multirow{5}{*}{\rotatebox{90}{ $ D0 $}}}& {\multirow{5}{*}{ }} & $ T_{1} $ & (A,5) (B,2) & 9\\ 
\cline{3-5}& & $ T_{2} $ & (A,2) (B,1) (D,1) & 6 \\
\cline{3-5}& & $ T_{3} $ & (E,1) (F,2) & 7 \\
\cline{3-5}& & $ T_{4} $ & (C,3) (D,2) & 13 \\
\cline{3-5}& & $ T_{5} $ & (A,2) (B,2) (C,1) (D,2) & 11 \\
\cline{2-5} {\multirow{3}{*}{\rotatebox{90}{ $ D1 $ }}}& & $ T_{6} $ & (A,3) (B,1) (E,2) & 15\\
\cline{3-5} & & $ T_{7} $ & (B,1) (D,1) (E,1) (F,1) & 10 \\
\cline{3-5} & & $ T_{8} $ & (A,2)  & 2 \\ 
\cline{3-5}
\end{tabular}
\label{table:1}
\end{minipage}
\begin{minipage}[t]{.25\linewidth}
\centering
\caption{Profit table}
\begin{tabular}{|c|c|} \hline
\textbf{Item} & \textbf{Profit} \\ \hline
\textbf{A} & 1 \\ \hline
\textbf{B} & 2 \\ \hline
\textbf{C} & 3\\ \hline
\textbf{D} & 2\\ \hline
\textbf{E} & 5\\ \hline
\textbf{F} & 1\\ \hline
\end{tabular}
\label{table:2}
\end{minipage}
\begin{minipage}[t]{.25\linewidth}
\centering
\caption{TWU table}
\begin{tabular}{|c|c|c|} \hline


\multicolumn{1}{|c}{\multirow{2}[0]{*}{\textbf{Item}}} & \multicolumn{2}{|c|}{\textbf{TWU}} \\
\cline{2-3}\multicolumn{1}{|c|}{} & $ D0 $    & $ D0+D1 $ \\
\cline{1-3}
\textbf{A} & 26& 43\\ \hline
\textbf{B} & 26& 51 \\ \hline
\textbf{C} & 24& 24\\ \hline
\textbf{D} & 30& 40 \\ \hline
\textbf{E} & 7& 32\\ \hline
\textbf{F} & 7& 17\\ \hline
\end{tabular}
\label{table:3}
\end{minipage}

\end{table}

%\newtheorem{theorem}{Definition}
\begin{definition} %[utility of an itemset]
The utility of an itemset $ X $ is denoted as $ U(X) $. 
\begin{equation}
U(X) = \sum_{X \subseteq T_{d} \in D} \sum_{i_{j} \in X} p(i_{j}) \times q(i_{j},T_{d})
\end{equation}
\end{definition}
%\newtheorem{theorem}{Definition}
\begin{definition} %[high Utility mining]
An itemset $ X $ is a high utility itemset if $ U(X) \ge min\_util $. High utility mining is to find the set of all itemsets $ \mathbf{X} = \{X_{1},X_{2},\ldots,X_{m}\} $ satisfies the condition that $ \forall X_{i} \in \mathbf{X}, U(X_{i}) \ge min\_util $. 
\end{definition}

After we define utility mining problem, we introduce TWU \cite{Liu:two-phasewithCCPD} which helps build up iCHUM-Tree and implement high utility mining algorithm.

\begin{definition} 
The transaction-weighted utility (TWU) of an itemset $ X $ denoted as $ TWU(X) $ is the sum of the transaction utilities (TU) of all transactions containing $ X $, shown as Table~\ref{table:3}.  
\begin{equation}
TWU(X) = \sum_{X \subseteq T_{d} \in D}TU(T_{d}) = \sum_{X \subseteq T_{d} \in D} \sum_{i_{j} \in T_{d}} p(i_{j}) \times q(i_{j},T_{d})
\end{equation}
\end{definition}

Noted that $ U(X) \le TWU(X) $ for $ \forall X $, if $ U(X) \ge min\_util $, then $ TWU(X) \ge min\_util $. That $ TWU(X) \ge min\_util $ just means that $ X $ is a high TWU itemset. However, $ TWU(X) $ satisfies downward closure property, according to which we could find all high TWU itemsets methodically. Therefore, high utility mining problem divides into high TWU mining and its utility identification, which constitutes the framework of our algorithm.

\subsection{iCHUM Framework}
The framework of iCHUM includes four procedure, that is iCHUM-Tree construction, iCHUM-Tree update, mining procedure and candidates identifying, shown as Fig.~\ref{fig:framework}. The overall input consists of transaction database and a $ min\_util $. The final output is the set of all high utility itemsets. Actually, for incremental databases, we have two parts of transaction database, the original database $ D0 $ and the new database $ D1 $. 

Construction and update of iCHUM-Tree are our feature procedure. We firstly construct iCHUM-Tree from $ D0 $, and obtain high utility itemsets following the flow chart. Then, when $ D1 $ comes as an incremental database, the iCHUM-Tree is updated instead of being rebuilt. The updated iCHUM-Tree is the input of minig procedure, which produce the candidate itemsets with high TWU value. The mining procedure is a pattern-growth mining approach, referring to \cite{Ahmed:IHUP}. Final step of identifying is picking up real high utlity itemsets from the candidates. Thus, we achieve all high utility itemsets of the transaction database, which combines $ D0 $ and $ D1 $ as a whole.

\begin{figure}
\centering
\begin{minipage}[b]{0.4\textwidth}
\centering
\includegraphics[width=0.78\linewidth, scale=0.1]{./b.eps}
\caption{Framework of iCHUM}
\label{fig:framework}
\end{minipage}
\begin{minipage}[b]{0.56\textwidth}
\centering
\includegraphics[width=0.8\linewidth]{./all.eps}
\caption{Construction and update of iCHUM-Tree (a) after inserting $ T_{5} $, (b) after inserting $ T_{8} $}
\label{fig:tree}
\end{minipage}
\end{figure}

\subsection{iCHUM-Tree Construction and Update}
%Data structure
Our iCHUM-Tree consists of tree structure and its headtable $ H $ for traversal, shown in Fig.~\ref{fig:tree}. In iCHUM-Tree, the nodes includes name, TWU, count, parent node, brother node and a set of child nodes, expressed as $ \{ name\}:(count, TWU) $. In headtable, each entry consists of the item name, TWU and a link pointed to nodes with the same name in the iCHUM-Tree. 

\textbf{Construction of iCHUM-Tree} is to constrcut iCHUM-Tree from the original database, shown in Algorithm~\ref{alg:construct}. According to TWDC property, the items with low TWU cannot appear in high utility itemsets. Therefore, the headtable of iCHUM-Tree simply maintains the promising items of which TWU $ \ge min\_util $. Before each transaction record is inserted to iCHUM-Tree, we arrange the items in TWU desceding order. It is efficient for mining procedure when traversing braches from bottom to top orderly. When mining process enters entry of higher TWU items, it would not check those low TWU items. During insertion if an item has been existed, we add its count by one and its TWU by TU of current transaction. Therefore, each brach of the iCHUM represents possible itemsets appeared in transaction records inserted.

\begin{algorithm}
\caption{iCHUM-Tree Construction}
\begin{algorithmic}
\REQUIRE  $ D0 $ ,  $ min\_util $
\ENSURE  $ TWU $ , iCHUM-Tree, $ H $
\STATE{\textbf{scan} \textit{D0} to update $ TWU $ }
\STATE{\textbf{create } $ H $ for each $ i $ satisfying $ TWU[i] \ge min\_util $ in $ TWU $ descending order }
\STATE{}
\COMMENT{ /* The following is \textbf{scan} and \textbf{insert} process */}
\FOR{each $ T_{d} $ in $ D0 $ }
\STATE{\textbf{sort} $ T_{d} $ to $ T_{d}' $ in $ TWU $ descending order }
\STATE{\textbf{insert} i to iCHUM-Tree for each i $ \in H $ in $ T_{d}'$ }
\ENDFOR
\end{algorithmic}
\label{alg:construct}
\end{algorithm}

\textbf{Update of iCHUM-Tree} is performed when a new transaction database comes to be inserted based on original database, shown in Algorithm~\ref{alg:update}. In new database, there would exist such items of which TWU is high in the new but not in the original. Even, such items, called recalled items, may be high TWU items in the whole database, like E in Fig.~\ref{fig:tree}b. In this case, iCHUM need to find back recalled items from $ D0 $, and insert them to $ H $ as well as iCHUM-Tree. Then iCHUM-Tree should be updated in TWU descending order.

Let us give an example of the construction and update procedure. Considering $ D0 $ in Table~\ref{table:1}, we set the $ min\_util $ as 40\% of the sum of TU, which is 18.4. $ H $ is created with items of which TWU $ \ge $ 18.4. The promising items are ``D A B C'' in TWU descending order. We insert these items in each transaction by the order and formulate iCHUM-Tree in Fig.~\ref{fig:tree}a. When $ D1 $ comes, TWU of items changes and $ min\_util $ is 29.2. We insert E to the headtable and tree following the previous order. And we keep the umpromising item C because it had once been high TWU items. It is likely that it becomes high TWU item again in incremental databases. We rearrange the iCHUM-Tree in ``B A D E C'' order. 

\begin{algorithm}
\caption{iCHUM-Tree Update}
\label{alg:update}
\begin{algorithmic}
\REQUIRE $ D0 $ , $ D1 $ ,  $ min\_util $ ,$ TWU $, iCHUM-Tree of $ D0 $, $ H $ of $ D0 $
\ENSURE  updated iCHUM-Tree, updated $ H $
\STATE{\textbf{scan} $ D1 $ to update $ TWU $ and find recalled items $ I' $ }
\STATE{\textbf{Add} all i$' \in I' $ to $ H $  }
\STATE{\textbf{scan} $ D0 $ and \textbf{insert} i$ ' $ to iCHUM-Tree  }
\STATE{\textbf{scan} $ D1 $ and \textbf{insert} i $ \in H $ to iCHUM-Tree  }
\STATE{\textbf{update} $ H $ and iCHUM-Tree by bubble sort operation }

\end{algorithmic}
\end{algorithm}

\section{Experimental Evaluation}
%my experiment and evaluation
In this section, we evaluate the performance of iCHUM algorithm written in C++. The experiment were conducted on Ubuntu server with a dual-2.4GHz CPU processor and 4G memory. Both real and synthetic dataset could be obtained from NU-MineBench \footnote{http://cucis.ece.northwestern.edu/projects/DMS/MineBench.html}. Real dataset, named \textit{Chainstore}, is a sparse and large database. It contains 1,112,949 transaction records and total 46,086 kinds of items. We split the database into $ D0 $ of 700,000 and $ D1 $ of 412,949. Synthetic dataset, named T10I6D100, contains 100 items and 93,058 transaction records of which average length is 10, where $ |D0| $ is 60,000 and $ |D1| $ is 33,058.

As a comparison, we implement IHUP algorithm and a iCHUM brute force (iCHUM-BF) algorithm in C++ as baseline. The iCHUM-BF algorithm is mining iCHUM-Tree twice without update procedure regarding the $ D0 $ and $ D0+D1 $ as original database input respectively.

\begin{figure}
\centering
\begin{minipage}[b]{0.48\textwidth}
\centering
\includegraphics[width=0.8\linewidth]{./e2.eps}
\caption{Runtime on T10I6D100}
\label{fig:synthetic}
\end{minipage}
\begin{minipage}[b]{0.48\textwidth}
\centering
\includegraphics[width=0.8\linewidth]{./e1.eps}
\caption{Runtime on Chainstore}
\label{fig:real}
\end{minipage}
\end{figure}

Fig.~\ref{fig:synthetic} shows the execution runtime on synthetic T10I6D100. For larger $ min\_util $ or minimum utility, runtime of iCHUM is less on construction and update of tree structure, shown in Table~\ref{table:4}. Howerver, performace of iCHUM becomes worse when $ min\_util $ gets small compared to IHUP. It is because that the number of items with high TWU reaches close to the total number of items. The cost of maintaining headtable is almost the same. Besides, iCHUM should spend more time on finding back recalled items. That happens in such a dataset, where there are less items and transaction length is longer. The iCHUM has an advantage over IHUP on sparse and large database, shown as Fig.~\ref{fig:real} and Table~\ref{table:4}. In chainstore, each item accounts for small proportion of whole transaction, where maintaining headtable with high TWU items is efficient. From runtime distribution in Table~\ref{table:4}, runtime is reduced in construction and update process, which our iCHUM algorithm focuses on.



\begin{table}
\centering
\caption{Runtime Distribution (sec.) of iCHUM and IHUP}
\begin{tabular}{c*{7}{c}r}
\hline
\multirow{2}[0]{*}{Dataset}  & \multicolumn{1}{c}{\multirow{2}[0]{*}{Algorithm}}  & \multicolumn{3}{c}{D0}  &\multicolumn{3}{c}{D1}  & \multicolumn{1}{c}{\multirow{2}[0]{*}{Time}} \\
 & \multicolumn{1}{c}{}  & construction & mining& identifying  & update & mining  & identifying & \multicolumn{1}{c}{}  \\
\hline
T10I6D100   & IHUP &  33.89 &  0.27     & 0.07  &    67.40   & 0.42      &  0.22     & 102.27 \\
$  0.5 \% $ & iCHUM &   30.60    &   0.26    &   0.07   &  62.64     &   0.41    &    0.22   & 94.20 \\
\hline
Chainstore & IHUP   &   209.14    &   1.45   &    46.09   &   318.78    &   2.29   &   73.86    & 651.61 \\
$ 0.2 \% $ & iCHUM &   113.98    &  1.33      &  46.00     &  199.74     &   2.18    &  72.63     & 435.86 \\
\hline
\end{tabular}
\label{table:4}
\end{table}


\section{Conclusions}
In this paper, we propose an efficient algorithm iCHUM for mining high utility itemsets in incremental databases. The iCHUM-Tree compress transaction database into compact tree structure. The update of iCHUM-Tree maintain list of all promising items which guarantee find all high utility itemsets. Experiment analysis shows that iCHUM-Tree performs better than other baselines in incremental databases, especially in terms of those with large number of transaction records or items. 

%\end{document}  % This is where a 'short' article might terminate

%ACKNOWLEDGMENTS are optional
%\section*{Acknowledgments}
%The authors would like to gratitude to Berkin Ozisikyilmaz from Northwestern University. His useful help largely contribute to our dataset making.


\bibliographystyle{abbrv}
\bibliography{sigproc}

\end{document}
